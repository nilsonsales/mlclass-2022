{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex  length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0   M   0.535     0.420   0.150        0.6995          0.2575          0.1530   \n",
       "1   I   0.510     0.380   0.115        0.5155          0.2150          0.1135   \n",
       "2   I   0.185     0.130   0.045        0.0290          0.0120          0.0075   \n",
       "3   M   0.550     0.450   0.170        0.8100          0.3170          0.1570   \n",
       "4   I   0.535     0.415   0.150        0.5765          0.3595          0.1350   \n",
       "\n",
       "   shell_weight  type  \n",
       "0        0.2400     3  \n",
       "1        0.1660     1  \n",
       "2        0.0095     1  \n",
       "3        0.2200     3  \n",
       "4        0.2250     1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/nilsonsales/mlclass-2022/master/03_Validation/abalone_dataset.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1078\n",
       "3    1051\n",
       "2    1003\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the classes are balanced\n",
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "data_mod = data.copy()\n",
    "Q1 = data_mod.quantile(0.25)\n",
    "Q3 = data_mod.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "data_mod = data_mod[~((data_mod < (Q1 - 1.5 * IQR)) |(data_mod > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3011, 10)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_mod[ data_mod.columns[:-1] ]\n",
    "y = data_mod['type']\n",
    "\n",
    "# Enconding the sex to a OneHotEncoding format\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.037969</td>\n",
       "      <td>0.300298</td>\n",
       "      <td>-0.137260</td>\n",
       "      <td>-0.367350</td>\n",
       "      <td>-0.118401</td>\n",
       "      <td>0.163386</td>\n",
       "      <td>-0.665907</td>\n",
       "      <td>-0.704115</td>\n",
       "      <td>1.329460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.231265</td>\n",
       "      <td>-0.406049</td>\n",
       "      <td>-0.677322</td>\n",
       "      <td>-0.586984</td>\n",
       "      <td>-0.612197</td>\n",
       "      <td>-0.554721</td>\n",
       "      <td>-0.453637</td>\n",
       "      <td>-0.665907</td>\n",
       "      <td>1.420223</td>\n",
       "      <td>-0.752185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.149014</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.888888</td>\n",
       "      <td>0.114795</td>\n",
       "      <td>-0.045116</td>\n",
       "      <td>-0.076347</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>-0.665907</td>\n",
       "      <td>-0.704115</td>\n",
       "      <td>1.329460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002786</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.300298</td>\n",
       "      <td>-0.433376</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>-0.312381</td>\n",
       "      <td>0.043676</td>\n",
       "      <td>-0.665907</td>\n",
       "      <td>1.420223</td>\n",
       "      <td>-0.752185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.871910</td>\n",
       "      <td>2.216477</td>\n",
       "      <td>1.972958</td>\n",
       "      <td>1.916002</td>\n",
       "      <td>1.247082</td>\n",
       "      <td>2.206303</td>\n",
       "      <td>2.104631</td>\n",
       "      <td>1.501711</td>\n",
       "      <td>-0.704115</td>\n",
       "      <td>-0.752185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     length  diameter    height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0  0.002786  0.037969  0.300298     -0.137260       -0.367350       -0.118401   \n",
       "1 -0.231265 -0.406049 -0.677322     -0.586984       -0.612197       -0.554721   \n",
       "2  0.149014  0.400576  0.888888      0.114795       -0.045116       -0.076347   \n",
       "3  0.002786 -0.019950  0.300298     -0.433376        0.171700       -0.312381   \n",
       "4  1.871910  2.216477  1.972958      1.916002        1.247082        2.206303   \n",
       "\n",
       "   shell_weight     sex_F     sex_I     sex_M  \n",
       "0      0.163386 -0.665907 -0.704115  1.329460  \n",
       "1     -0.453637 -0.665907  1.420223 -0.752185  \n",
       "2      0.003192 -0.665907 -0.704115  1.329460  \n",
       "3      0.043676 -0.665907  1.420223 -0.752185  \n",
       "4      2.104631  1.501711 -0.704115 -0.752185  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# normalizer = PowerTransformer().fit(X)\n",
    "\n",
    "# X_mod = pd.DataFrame(normalizer.transform(X), columns = X.columns)\n",
    "\n",
    "# X_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3011, 10)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estratégia pra usar PCA\n",
    "from sklearn.decomposition import PCA  # Make an instance of the Model\n",
    "\n",
    "X_mod = X\n",
    "\n",
    "#pca = PCA(n_components='mle')\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(X_mod)\n",
    "X_mod = pca.transform(X_mod)\n",
    "\n",
    "X_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting our data into train and validation (calling it test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mod, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####### Training Models #######\n",
      "\n",
      "Model:  LogisticRegression\n",
      "Train accuracy: 0.6274910482200476\n",
      "Val accuracy: 0.615257048092869\n",
      "Confusion matrix:\n",
      "[[165  43   6]\n",
      " [ 49  89  56]\n",
      " [ 28  50 117]]\n",
      "\n",
      "Model:  SVC\n",
      "Train accuracy: 0.6204362485235645\n",
      "Val accuracy: 0.615257048092869\n",
      "Confusion matrix:\n",
      "[[164  47   3]\n",
      " [ 54  96  44]\n",
      " [ 28  56 111]]\n",
      "\n",
      "Model:  SVC\n",
      "Train accuracy: 0.6424375963370942\n",
      "Val accuracy: 0.6517412935323383\n",
      "Confusion matrix:\n",
      "[[150  55   9]\n",
      " [ 26 119  49]\n",
      " [ 15  56 124]]\n",
      "\n",
      "Model:  RandomForestClassifier\n",
      "Train accuracy: 0.6490814267775973\n",
      "Val accuracy: 0.6583747927031509\n",
      "Confusion matrix:\n",
      "[[164  38  12]\n",
      " [ 35 106  53]\n",
      " [ 14  54 127]]\n",
      "\n",
      "Model:  MLPClassifier\n",
      "Train accuracy: 0.6611284159878427\n",
      "Val accuracy: 0.6749585406301825\n",
      "Confusion matrix:\n",
      "[[158  47   9]\n",
      " [ 25 121  48]\n",
      " [ 12  55 128]]\n",
      "The best model is:  MLPClassifier with validation accuracy of  0.6749585406301825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def select_best_model(X_train, X_test, y_train, y_test):\n",
    "    model_1 = LogisticRegression(random_state=42, max_iter=3000)\n",
    "    model_2 = SVC(kernel='linear', probability=False)\n",
    "    model_3 = SVC(kernel='rbf', C=14, gamma=0.5)\n",
    "    #model_4 = RandomForestClassifier(max_depth=90, min_samples_split=12, n_estimators=42)\n",
    "    model_4 = RandomForestClassifier(n_estimators=84, min_samples_split=10, min_samples_leaf=10, max_features='sqrt', max_depth=20, bootstrap=True)\n",
    "    model_5 = MLPClassifier(solver='adam', alpha=0.0001, max_iter=1000, random_state=42)\n",
    "\n",
    "    models = [model_1, model_2, model_3, model_4, model_5]\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    print(\"\\n####### Training Models #######\")\n",
    "\n",
    "    for model in models:\n",
    "        print(\"\\nModel: \", type(model).__name__)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=3))\n",
    "        print(f'Train accuracy: {train_accuracy}')\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        val_accuracy = accuracy_score(y_test, y_pred)\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Val accuracy: {val_accuracy}\\nConfusion matrix:\\n{confusion}\")\n",
    "        \n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_model = model\n",
    "            best_accuracy = val_accuracy\n",
    "\n",
    "    print(\"The best model is: \", type(best_model).__name__, \"with validation accuracy of \", best_accuracy)\n",
    "    return best_model\n",
    "\n",
    "\n",
    "model = select_best_model(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant'}\n",
      "0.65615 (+/-0.004) for {'alpha': 0.0001, 'hidden_layer_sizes': (50, 40, 40), 'learning_rate': 'constant'}\n",
      "0.65781 (+/-0.008) for {'alpha': 0.0001, 'hidden_layer_sizes': (50, 40, 40), 'learning_rate': 'adaptive'}\n",
      "0.65740 (+/-0.016) for {'alpha': 0.0001, 'hidden_layer_sizes': (60, 40), 'learning_rate': 'constant'}\n",
      "0.66196 (+/-0.015) for {'alpha': 0.0001, 'hidden_layer_sizes': (60, 40), 'learning_rate': 'adaptive'}\n",
      "0.65407 (+/-0.009) for {'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant'}\n",
      "0.65739 (+/-0.006) for {'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive'}\n",
      "0.65283 (+/-0.015) for {'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.65822 (+/-0.013) for {'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.66238 (+/-0.017) for {'alpha': 0.001, 'hidden_layer_sizes': (50, 40, 40), 'learning_rate': 'constant'}\n",
      "0.65739 (+/-0.017) for {'alpha': 0.001, 'hidden_layer_sizes': (50, 40, 40), 'learning_rate': 'adaptive'}\n",
      "0.65946 (+/-0.014) for {'alpha': 0.001, 'hidden_layer_sizes': (60, 40), 'learning_rate': 'constant'}\n",
      "0.65656 (+/-0.014) for {'alpha': 0.001, 'hidden_layer_sizes': (60, 40), 'learning_rate': 'adaptive'}\n",
      "0.65656 (+/-0.002) for {'alpha': 0.001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant'}\n",
      "0.65822 (+/-0.010) for {'alpha': 0.001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive'}\n",
      "0.65615 (+/-0.004) for {'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.65864 (+/-0.015) for {'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.65697 (+/-0.011) for {'alpha': 0.01, 'hidden_layer_sizes': (50, 40, 40), 'learning_rate': 'constant'}\n",
      "0.65822 (+/-0.006) for {'alpha': 0.01, 'hidden_layer_sizes': (50, 40, 40), 'learning_rate': 'adaptive'}\n",
      "0.65407 (+/-0.009) for {'alpha': 0.01, 'hidden_layer_sizes': (60, 40), 'learning_rate': 'constant'}\n",
      "0.65531 (+/-0.013) for {'alpha': 0.01, 'hidden_layer_sizes': (60, 40), 'learning_rate': 'adaptive'}\n",
      "0.66445 (+/-0.019) for {'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant'}\n",
      "0.66238 (+/-0.013) for {'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive'}\n",
      "0.65739 (+/-0.009) for {'alpha': 0.01, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.65905 (+/-0.004) for {'alpha': 0.01, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.65033 (+/-0.023) for {'alpha': 0.05, 'hidden_layer_sizes': (50, 40, 40), 'learning_rate': 'constant'}\n",
      "0.65657 (+/-0.016) for {'alpha': 0.05, 'hidden_layer_sizes': (50, 40, 40), 'learning_rate': 'adaptive'}\n",
      "0.65905 (+/-0.014) for {'alpha': 0.05, 'hidden_layer_sizes': (60, 40), 'learning_rate': 'constant'}\n",
      "0.66321 (+/-0.023) for {'alpha': 0.05, 'hidden_layer_sizes': (60, 40), 'learning_rate': 'adaptive'}\n",
      "0.65241 (+/-0.011) for {'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant'}\n",
      "0.65116 (+/-0.006) for {'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive'}\n",
      "0.64493 (+/-0.011) for {'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.65615 (+/-0.002) for {'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "'''\n",
    "    Based on: https://datascience.stackexchange.com/a/36087/97065\n",
    "'''\n",
    "\n",
    "def find_best_mlp(X_train, X_test, y_train, y_test):\n",
    "    mlp = MLPClassifier(max_iter=1000, solver='adam')\n",
    "\n",
    "    parameter_space = {\n",
    "        'hidden_layer_sizes': [(50,40,40), (60,40), (50,50), (100,)], #[(50,50,50), (50,100,50), (100,)],\n",
    "        #'activation': ['tanh', 'relu'],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.05],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "\n",
    "\n",
    "    clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameter set\n",
    "    print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "    # All results\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.5f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "    return clf\n",
    "\n",
    "mlp = find_best_mlp(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6611294511748855\n",
      "Val accuracy: 0.6749585406301825\n",
      "Confusion matrix:\n",
      "[[158  47   9]\n",
      " [ 25 121  48]\n",
      " [ 12  55 128]]\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy again using the best parameters and use the validation set\n",
    "\n",
    "model2 = MLPClassifier(max_iter=1000)\n",
    "model2.set_params(**mlp.best_params_)\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "accuracy = np.mean(cross_val_score(model2, X_train, y_train, cv=3))\n",
    "print('Train accuracy: ', accuracy)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "val_accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Val accuracy: {val_accuracy}\\nConfusion matrix:\\n{confusion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.05, hidden_layer_sizes=(60, 40), learning_rate='adaptive',\n",
       "              max_iter=900)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using ALL the data available for a final model\n",
    "# Based on: https://datascience.stackexchange.com/questions/33008/is-it-always-better-to-use-the-whole-dataset-to-train-the-final-model\n",
    "\n",
    "# model3 = MLPClassifier(max_iter=1000)\n",
    "# model3.set_params(**mlp.best_params_)\n",
    "\n",
    "# model3.fit(X_mod, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 10)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_app = pd.read_csv('https://raw.githubusercontent.com/nilsonsales/mlclass-2022/master/03_Validation/abalone_app.csv')\n",
    "\n",
    "# Apply the same tranformation to the test set\n",
    "data_app = pd.get_dummies(data_app)\n",
    "\n",
    "#data_app\n",
    "\n",
    "# Apply PCA if used\n",
    "data_app = pca.transform(data_app)\n",
    "\n",
    "data_app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Aplicando modelo e enviando para o servidor\n",
      " - Resposta do servidor:\n",
      " {\"status\":\"success\",\"dev_key\":\"720pster\",\"accuracy\":0.6526315789473685,\"old_accuracy\":0.6622009569378} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' - Aplicando modelo e enviando para o servidor')\n",
    "\n",
    "y_pred = model2.predict(data_app)\n",
    "\n",
    "# Enviando previsões realizadas com o modelo para o servidor\n",
    "URL = \"https://aydanomachado.com/mlclass/03_Validation.php\"\n",
    "\n",
    "#TODO Substituir pela sua chave aqui\n",
    "DEV_KEY = \"720pster\"\n",
    "\n",
    "# json para ser enviado para o servidor\n",
    "data_json = {'dev_key':DEV_KEY,\n",
    "             'predictions':pd.Series(y_pred).to_json(orient='values')}\n",
    "\n",
    "# Enviando requisição e salvando o objeto resposta\n",
    "r = requests.post(url = URL, data = data_json)\n",
    "\n",
    "# Extraindo e imprimindo o texto da resposta\n",
    "pastebin_url = r.text\n",
    "print(\" - Resposta do servidor:\\n\", r.text, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant'} -> \"accuracy\":0.6602870813397129"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlclass')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "156716a13c09ed4bd8ae68ff669aa8217a1ecb5a72dc18e2f5e48a8889f317d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
